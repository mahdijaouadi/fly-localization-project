{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We understand our dataset\n",
    "    # We have very unbalanced data\n",
    "    # Many images are not clear at all (We can consider to remove them)\n",
    "    # \n",
    "## Balance the data\n",
    "## Understand the distribution of each class\n",
    "## Remove Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 11:12:56.639360: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-05 11:12:56.656242: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-05 11:12:56.660851: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 11:12:56.673172: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-05 11:12:57.605196: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preprocess(img):\n",
    "    img = img.resize((224,224))\n",
    "    img= np.array(img) \n",
    "    img=img/255.0\n",
    "    img=torch.from_numpy(img).to(torch.float32)\n",
    "    img = img.permute(2,0,1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = f'..//drone-detection-new.v5-new-train.yolov8//train//images'\n",
    "image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "label_folder = f'..//drone-detection-new.v5-new-train.yolov8//train//labels'\n",
    "# label_files = [f for f in os.listdir(label_folder) if os.path.isfile(os.path.join(label_folder, f))]\n",
    "data_list=[]\n",
    "for img_file in image_files:\n",
    "    try:\n",
    "        label_file=img_file[:-4]+'.txt'\n",
    "        with open(f'{label_folder}//{label_file}', 'r') as file:\n",
    "            content = file.read()\n",
    "        label=content.split(' ')\n",
    "        label=list(map(np.float32, label))\n",
    "        img = Image.open(f'{image_folder}//{img_file}')\n",
    "        img=img_preprocess(img)\n",
    "        data_list.append((img,label))\n",
    "    except:\n",
    "        pass\n",
    "with open(f'..//data//data.pkl', 'wb') as f:\n",
    "    pickle.dump(data_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n"
     ]
    }
   ],
   "source": [
    "#Techniques of images augmentation\n",
    "datagen_rotation = ImageDataGenerator(rotation_range=40)\n",
    "datagen_zoom = ImageDataGenerator(zoom_range=0.2)\n",
    "datagen_brightness = ImageDataGenerator(brightness_range=[0.8, 1.2])\n",
    "augmentation_list=[datagen_rotation,datagen_zoom,datagen_brightness]\n",
    "data_list=[]\n",
    "k=0\n",
    "for folder in folders:\n",
    "    image_folder = f'imagenet-a//{folder}'\n",
    "    files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "    n=len(files)\n",
    "    for file in files:\n",
    "        try:\n",
    "            image_path = image_folder+'//'+file\n",
    "            img = Image.open(image_path)\n",
    "            img_array = np.array(img)\n",
    "            img_array=img_preprocess(img_array)\n",
    "            data_list.append((img_array,folder))\n",
    "        except:\n",
    "            n-=1\n",
    "            pass\n",
    "    \n",
    "    while n<max_class:\n",
    "        try:\n",
    "            file=files[random.randint(0,len(files)-1)]\n",
    "            image_path = image_folder+'//'+file\n",
    "            img = Image.open(image_path)\n",
    "\n",
    "            img_array = np.array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0) \n",
    "\n",
    "            datagen = augmentation_list[random.randint(0,len(augmentation_list)-1)]\n",
    "            it = datagen.flow(img_array, batch_size=1)\n",
    "\n",
    "            augmented_image = next(it)\n",
    "            augmented_image = np.squeeze(augmented_image)\n",
    "            augmented_image = np.array(augmented_image)\n",
    "            augmented_image = (augmented_image * 255).astype('uint8')\n",
    "            augmented_image=img_preprocess(augmented_image)\n",
    "\n",
    "            data_list.append((augmented_image,folder))\n",
    "            n+=1\n",
    "        except:\n",
    "            pass\n",
    "        # print(n)\n",
    "    print(len(data_list))\n",
    "    # if len(data_list)%1000==0:\n",
    "\n",
    "    #     k+=1000\n",
    "    #     del data_list\n",
    "    #     data_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(data_list)\n",
    "\n",
    "# slice_window=1000\n",
    "# for i in range(0,len(data_list),slice_window):\n",
    "    # with open(f'data//data{i}.pkl', 'wb') as f:\n",
    "    #     pickle.dump(data_list[i:i+slice_window], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
